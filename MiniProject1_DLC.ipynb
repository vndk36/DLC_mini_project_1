{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is distributed under BSD 3-Clause license\n",
    "\n",
    "import torch\n",
    "import numpy\n",
    "import os\n",
    "import errno\n",
    "\n",
    "from torch import optim\n",
    "from torch import legacy\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "from six.moves import urllib\n",
    "\n",
    "#loss_plot = []\n",
    "\n",
    "def tensor_from_file(root, filename,\n",
    "                     base_url = 'https://documents.epfl.ch/users/f/fl/fleuret/www/data/bci'):\n",
    "\n",
    "    file_path = os.path.join(root, filename)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        try:\n",
    "            os.makedirs(root)\n",
    "        except OSError as e:\n",
    "            if e.errno == errno.EEXIST:\n",
    "                pass\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        url = base_url + '/' + filename\n",
    "\n",
    "        print('Downloading ' + url)\n",
    "        data = urllib.request.urlopen(url)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(data.read())\n",
    "\n",
    "    return torch.from_numpy(numpy.loadtxt(file_path))\n",
    "\n",
    "def load(root, train = True, download = True, one_khz = False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "\n",
    "        root (string): Root directory of dataset.\n",
    "\n",
    "        train (bool, optional): If True, creates dataset from training data.\n",
    "\n",
    "        download (bool, optional): If True, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "\n",
    "        one_khz (bool, optional): If True, creates dataset from the 1000Hz data instead\n",
    "            of the default 100Hz.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    nb_electrodes = 28\n",
    "\n",
    "    if train:\n",
    "\n",
    "        if one_khz:\n",
    "            dataset = tensor_from_file(root, 'sp1s_aa_train_1000Hz.txt')\n",
    "        else:\n",
    "            dataset = tensor_from_file(root, 'sp1s_aa_train.txt')\n",
    "\n",
    "        input = dataset.narrow(1, 1, dataset.size(1) - 1)\n",
    "        input = input.float().view(input.size(0), nb_electrodes, -1)\n",
    "        target = dataset.narrow(1, 0, 1).clone().view(-1).long() #changer le type suivant le loss criterion\n",
    "\n",
    "    else:\n",
    "\n",
    "        if one_khz:\n",
    "            input = tensor_from_file(root, 'sp1s_aa_test_1000Hz.txt')\n",
    "        else:\n",
    "            input = tensor_from_file(root, 'sp1s_aa_test.txt')\n",
    "        target = tensor_from_file(root, 'labels_data_set_iv.txt')\n",
    "\n",
    "        input = input.float().view(input.size(0), nb_electrodes, -1)\n",
    "        target = target.view(-1).long() #changer le type suivant le loss criterion\n",
    "\n",
    "    return input, target\n",
    "            \n",
    "#################################################################\n",
    "\n",
    "def compute_nb_errors(model, data_input, data_target, mini_batch_size):\n",
    "\n",
    "    nb_data_errors = 0\n",
    "    model.eval()\n",
    "    for b in range(0, data_input.size(0), mini_batch_size):\n",
    "        output = model(data_input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = torch.max(output.data, 1)\n",
    "        for k in range(0, mini_batch_size):\n",
    "            if data_target.data[b + k] != predicted_classes[k]:\n",
    "                nb_data_errors = nb_data_errors + 1\n",
    "\n",
    "    return nb_data_errors\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data, Increase the Dataset and Create Validation Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target = load(\"data\",True, False)\n",
    "test_input, test_target = load(\"data\",False, False)\n",
    "train_input, train_target, test_input, test_target = \\\n",
    "Variable(train_input), Variable(train_target), Variable(test_input), Variable(test_target)\n",
    "\n",
    "def valSet(train_input, train_target,sizeVal):\n",
    "    \n",
    "    permutation = torch.randperm(train_input.size()[0])\n",
    "    \n",
    "    validation_set_input=train_input[permutation].narrow(0,0,sizeVal)\n",
    "    validation_set_target=train_target[permutation].narrow(0,0,sizeVal)\n",
    "    new_train_input=train_input[permutation].narrow(0,sizeVal,train_input.size()[0]-sizeVal)\n",
    "    new_train_target=train_target[permutation].narrow(0,sizeVal,train_input.size()[0]-sizeVal)\n",
    "    \n",
    "    return new_train_input, new_train_target, validation_set_input, validation_set_target\n",
    "\n",
    "train_input, train_target, validation_set_input, validation_set_target = valSet(train_input, train_target, 16)\n",
    "\n",
    "\n",
    "print(train_input.size())\n",
    "print(train_target.size())\n",
    "print(validation_set_input.size())\n",
    "print(validation_set_target.size())\n",
    "\n",
    "#adding white noise to the signal\n",
    "dataNoisy=Variable(torch.Tensor(train_input.size()))\n",
    "for i in range(0,train_input.size(0)):\n",
    "    for j in range(0,train_input.size(1)):\n",
    "        noise = numpy.random.normal(0,5,50) #vector of 50 values with normal distribution of mean=0, std=2\n",
    "        #noise = numpy.random.uniform(-2,2, 50)\n",
    "        noiseVar=Variable(torch.Tensor(noise))\n",
    "        dataNoisy[i,j,:]=train_input[i,j,:].add(noiseVar)\n",
    "\n",
    "\n",
    "\n",
    "#adding white noise to the signal\n",
    "dataNoisy2=Variable(torch.Tensor(train_input.size()))\n",
    "for i in range(0,train_input.size(0)):\n",
    "    for j in range(0,train_input.size(1)):\n",
    "        noise = numpy.random.normal(0,10,50) #vector of 50 values with normal distribution of mean=0, std=4\n",
    "        #noise = numpy.random.uniform(-4,4,50)\n",
    "        noiseVar=Variable(torch.Tensor(noise))\n",
    "        dataNoisy2[i,j,:]=train_input[i,j,:].add(noiseVar)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#verification\n",
    "plt.plot(train_input[30,10,:].data.numpy())\n",
    "plt.plot(dataNoisy[30,10,:].data.numpy())\n",
    "\n",
    "train_input = torch.cat((train_input, dataNoisy), 0) #the two matrices are concatenated\n",
    "train_input = torch.cat((train_input, dataNoisy2), 0)\n",
    "\n",
    "new_train_target=torch.cat((train_target, train_target), 0)\n",
    "train_target=torch.cat((new_train_target, train_target), 0)\n",
    "\n",
    "train_input = train_input.sub_(train_input.data.mean()).div_(train_input.data.std())\n",
    "test_input = test_input.sub_(test_input.data.mean()).div_(test_input.data.std())\n",
    "validation_set_input = validation_set_input.sub_(validation_set_input.data.mean()).div_(validation_set_input.data.std())\n",
    "\n",
    "print(train_input.size())\n",
    "print(train_target.size())\n",
    "print(validation_set_input.size())\n",
    "print(validation_set_target.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, loss_plot, nb_epochs, batch_size, lr):\n",
    "    step_size = 20\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #optimizer = optim.SGD(model.parameters(), lr = lr)\n",
    "    optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "    \n",
    "    #Optimizer to update the Learning rate\n",
    "    scheduler = 0\n",
    "# Activate one of the two step optimizer if you want to have one\n",
    "\n",
    "    #scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', verbose=True, threshold=1, factor=0.5, patience = 30 )\n",
    "    #scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = step_size, gamma=0.1, last_epoch=-1)\n",
    "   \n",
    "    \n",
    "    for e in range(0, nb_epochs):\n",
    "        permutation = torch.randperm(train_input.size()[0])\n",
    "        sum_loss = 0\n",
    "        for b in range(0, train_input.size(0), batch_size):\n",
    "            indices = permutation[b:b+batch_size]\n",
    "            batch_input, batch_target = train_input[indices], train_target[indices]\n",
    "            \n",
    "            output = model(batch_input)\n",
    "            loss = criterion(output, batch_target)\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss = sum_loss + loss\n",
    "            \n",
    "        #print(\"The loss is :\"+str(loss)+\" for epoch :\"+str(e))\n",
    "        loss_plot.append(sum_loss.data.numpy())\n",
    "        #print(str(int((e/nb_epochs)*100))+\"%\")\n",
    "        if sum_loss.data.numpy()< 0.01:\n",
    "            break\n",
    "        if scheduler != 0:\n",
    "\n",
    "            #scheduler.step(sum_loss.data.numpy())\n",
    "            scheduler.step()\n",
    "            \n",
    "    return e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "\n",
    "#lr 1e-5 100 epochs\n",
    "class Net_lin_dropout(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(Net_lin_dropout, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*50,1000)\n",
    "        self.fc2 = nn.Linear(1000, 400)\n",
    "        self.fc3 = nn.Linear(400, 20)\n",
    "        self.fc4 = nn.Linear(20, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x.view(-1,x.data.size()[1]* x.data.size()[2])))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        nn.Dropout()\n",
    "        x = F.relu(self.fc3(x))\n",
    "        nn.Dropout()\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "####################################################################################################################\n",
    "\n",
    "\n",
    "class Net_basic(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(Net_basic, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(28, 64, kernel_size=5)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3)\n",
    "        self.conv3 = nn.Conv1d(128, 128, kernel_size=2)\n",
    "        self.fc1 = nn.Linear(128*3, nb_hidden*3)\n",
    "        self.fc2 = nn.Linear(nb_hidden*3, nb_hidden*2)\n",
    "        self.fc3 = nn.Linear(nb_hidden*2, nb_hidden)\n",
    "        self.fc4 = nn.Linear(nb_hidden, 2)\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.dropout(x)\n",
    "        x = F.relu(F.max_pool1d(self.conv1(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool1d(self.conv2(x), kernel_size=3, stride=3))\n",
    "        x = F.relu(F.max_pool1d(self.conv3(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1,x.data.size()[1]* x.data.size()[2])))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "#model = nn.Sequential(\n",
    "    #nn.Conv1d(28, 32, kernel_size=5), \n",
    "    #nn.ReLU(),\n",
    "    #nn.Conv1d(56, 56, kernel_size=4, stride = 2),\n",
    "    #nn.ReLU(),\n",
    "    #nn.MaxPool1d(kernel_size = 5, stride = 3),\n",
    "    #nn.ReLU(),\n",
    "    #nn.Conv1d(56,56, kernel_size = 4, stride = 1),\n",
    "    #nn.ReLU(),\n",
    "    #nn.Linear(32*46,79),\n",
    "    #nn.ReLU(),\n",
    "    #nn.Linear(79, 2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_lin(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(Net_lin, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*50,1000)\n",
    "        self.fc2 = nn.Linear(1000, 400)\n",
    "        self.fc3 = nn.Linear(400, 20)\n",
    "        self.fc4 = nn.Linear(20, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x.view(-1,x.data.size()[1]* x.data.size()[2])))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method seen on https://onlinelibrary.wiley.com/doi/full/10.1002/hbm.23730\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=(1,6))\n",
    "        self.conv2 =  nn.Conv2d(28, 1, kernel_size=(1,1))\n",
    "        self.conv3 = nn.Conv1d(20, 40, kernel_size=10)\n",
    "        self.conv4 = nn.Conv1d(40, 80, kernel_size=4)\n",
    "        self.conv5 = nn.Conv1d(80, 160, kernel_size=4)\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(160*2, nb_hidden*3)\n",
    "        \n",
    "        self.fc2 = nn.Linear(nb_hidden*3, nb_hidden)\n",
    "        self.fc3 = nn.Linear(nb_hidden, 2)\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Nx28*50\n",
    "        #print(x.size())\n",
    "        x=x.unsqueeze(1) #Nx1x28x50\n",
    "        #print(x.size())\n",
    "        x=F.elu(self.conv1(x),alpha=4.0, inplace = True ) #Nx20x28x45\n",
    "        #print(x.size())\n",
    "        x=x.transpose(1,2) #Nx28x20x45\n",
    "        #print(x.size())\n",
    "        x=F.elu(self.conv2(x)) #Nx1x20x45\n",
    "        #print(\"efwef\"+str(x.size()))\n",
    "        \n",
    "        \n",
    "        x=x.squeeze() #Nx20x45\n",
    "        #print(x.size())\n",
    "        #time.sleep(10)\n",
    "        x = F.relu(F.max_pool1d(x,4,stride = 1)) #Nx20x42\n",
    "        \n",
    "        \n",
    "        x = F.relu(F.max_pool1d(self.conv3(x), kernel_size=4,stride = 1 )) #Nx40x33 -> Nx40x30\n",
    "        \n",
    "        \n",
    "        x = F.relu(F.max_pool1d(self.conv4(x), kernel_size=3,stride = 3 )) #Nx80x27 -> Nx80x9\n",
    "        \n",
    "        \n",
    "        x = F.relu(F.max_pool1d(self.conv5(x), kernel_size=3,stride = 3 )) #Nx160x6 -> Nx160x2   \n",
    "        \n",
    "        \n",
    "        \n",
    "        x = F.relu(self.fc1(x.view(-1,x.data.size()[1]* x.data.size()[2])))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetSWAG(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(NetSWAG, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(28, 64, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3)\n",
    "        #self.conv3 = nn.Conv1d(32, 32, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(128*11, nb_hidden)\n",
    "        \n",
    "        self.fc2 = nn.Linear(nb_hidden*3, nb_hidden)\n",
    "        self.fc3 = nn.Linear(nb_hidden, 2)\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool1d(self.conv1(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool1d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        #x = F.relu(F.max_pool1d(self.conv3(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1,x.data.size()[1]* x.data.size()[2])))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        #x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetDROP(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(NetDROP, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(28, 64, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3)\n",
    "        self.conv3 = nn.Conv1d(128, 256, kernel_size=4)\n",
    "        self.fc1 = nn.Linear(256*4, 3*nb_hidden)\n",
    "        \n",
    "        self.fc2 = nn.Linear(nb_hidden*3, nb_hidden)\n",
    "        self.fc3 = nn.Linear(nb_hidden, 2)\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool1d(self.conv1(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool1d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool1d(self.conv3(x), kernel_size=2, stride=2))\n",
    "        #x = F.relu(F.max_pool1d(self.conv3(x), kernel_size=2, stride=2))\n",
    "        x=self.dropout(x)\n",
    "        x = F.relu(self.fc1(x.view(-1,x.data.size()[1]* x.data.size()[2])))\n",
    "        x=self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x=self.dropout(x)\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        #x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetGIT(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(NetGIT, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(28, 64, kernel_size=5)\n",
    "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3)\n",
    "        self.conv3 = nn.Conv1d(128, 128, kernel_size=2)\n",
    "        self.fc1 = nn.Linear(128*3, nb_hidden*3)\n",
    "        self.fc2 = nn.Linear(nb_hidden*3, nb_hidden*2)\n",
    "        self.fc3 = nn.Linear(nb_hidden*2, nb_hidden)\n",
    "        self.fc4 = nn.Linear(nb_hidden, 2)\n",
    "        self.dropout = nn.Dropout()\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.dropout(x)\n",
    "        x = F.relu(F.max_pool1d(self.conv1(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool1d(self.conv2(x), kernel_size=3, stride=3))\n",
    "        x = F.relu(F.max_pool1d(self.conv3(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1,x.data.size()[1]* x.data.size()[2])))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_convnet(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(Net_convnet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(28, 64, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(64*11, nb_hidden)\n",
    "        self.fc3 = nn.Linear(nb_hidden, 2)        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool1d(self.conv1(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool1d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1,x.data.size()[1]* x.data.size()[2])))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_convnet_dropout(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(Net_convnet_dropout, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(28, 64, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(64*11, nb_hidden)\n",
    "        self.fc3 = nn.Linear(nb_hidden, 2)        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool1d(self.conv1(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool1d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        nn.Dropout()\n",
    "        x = F.relu(self.fc1(x.view(-1,x.data.size()[1]* x.data.size()[2])))\n",
    "        nn.Dropout()\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetOLDANDDUMB2(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(NetOLDANDDUMB2, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(28, 64, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size=3)\n",
    "        #self.conv3 = nn.Conv1d(32, 32, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(64*11, nb_hidden)\n",
    "        \n",
    "        self.fc2 = nn.Linear(nb_hidden, 30)\n",
    "        self.fc3 = nn.Linear(30, 2)\n",
    "        #self.dropout = nn.Dropout()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        nn.Dropout(p = 0.7)\n",
    "        x = F.relu(F.max_pool1d(self.conv1(x), kernel_size=2, stride=2))\n",
    "        nn.Dropout(p = 0.7)\n",
    "        x = F.relu(F.max_pool1d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        #x = F.relu(F.max_pool1d(self.conv3(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1,x.data.size()[1]* x.data.size()[2])))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        #x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the right model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select you model here!!!\n",
    "#||||||||||||||||||||||||\n",
    "#VVVVVVVVVVVVVVVVVVVVVVVV\n",
    "\n",
    "model = Netbasic(150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_error 0.00% validation_set_error 43.75% test_error 27.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f39d6b2c320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_error AVG 0.00% validation_set_error AVG 43.75% test_error AVG 27.00%\n",
      "train_error BEST 0.00% validation_set_error BEST 43.75% test_error BEST 27.00%\n",
      "\n",
      "\n",
      "\n",
      "train_error 0.00% validation_set_error 37.50% test_error 29.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f39d6a03f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_error AVG 0.00% validation_set_error AVG 40.62% test_error AVG 28.00%\n",
      "train_error BEST 0.00% validation_set_error BEST 37.50% test_error BEST 27.00%\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test multiple prior init\n",
    "\n",
    "# Select you model here!!!\n",
    "#||||||||||||||||||||||||\n",
    "#VVVVVVVVVVVVVVVVVVVVVVVV\n",
    "\n",
    "model = Net_lin_dropout(150)\n",
    "\n",
    "\n",
    "nb_epochs =  100\n",
    "batch_size = 50\n",
    "\n",
    "lr = 1e-4\n",
    "\n",
    "\n",
    "nb_training = 20\n",
    "\n",
    "train_error = []\n",
    "validation_error = []\n",
    "test_error = []\n",
    "\n",
    "for i in range(0,nb_training):\n",
    "    for p in model.parameters(): p.data.normal_(0, 0.01)\n",
    "    loss_plot = []\n",
    "    epochs_reached = train_model(model, train_input, train_target, loss_plot, nb_epochs, batch_size = batch_size, lr = lr)\n",
    "    \n",
    "    train_error.append(compute_nb_errors(model, train_input, train_target, 10) / train_input.size(0) * 100)\n",
    "    validation_error.append(compute_nb_errors(model, validation_set_input, validation_set_target, 16) / validation_set_input.size(0) * 100)\n",
    "    test_error.append(compute_nb_errors(model, test_input, test_target, 50) / test_input.size(0) * 100)\n",
    "  \n",
    "    print('train_error {:.02f}% validation_set_error {:.02f}% test_error {:.02f}%'.format(train_error[i], validation_error[i], test_error[i]))\n",
    "    #loss_plot\n",
    "    for p in model.parameters(): p.data.normal_(0, 0.01)\n",
    "    plt.plot(range(epochs_reached+1),loss_plot)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    print('train_error AVG {:.02f}% validation_set_error AVG {:.02f}% test_error AVG {:.02f}%'.format(\n",
    "        numpy.asarray(train_error).mean(), \n",
    "        numpy.asarray(validation_error).mean(), \n",
    "        numpy.asarray(test_error).mean()))\n",
    "    print('train_error BEST {:.02f}% validation_set_error BEST {:.02f}% test_error BEST {:.02f}%\\n\\n\\n'.format(\n",
    "        numpy.asarray(train_error).min(), \n",
    "        numpy.asarray(validation_error).min(), \n",
    "        numpy.asarray(test_error).min()))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test multiple prior init\n",
    "\n",
    "# Select you model here!!!\n",
    "#||||||||||||||||||||||||\n",
    "#VVVVVVVVVVVVVVVVVVVVVVVV\n",
    "\n",
    "model = Net_lin(150)\n",
    "\n",
    "\n",
    "nb_epochs =  100\n",
    "batch_size = 50\n",
    "\n",
    "lr = 1e-4\n",
    "\n",
    "\n",
    "nb_training = 20\n",
    "\n",
    "train_error = []\n",
    "validation_error = []\n",
    "test_error = []\n",
    "\n",
    "for i in range(0,nb_training):\n",
    "    for p in model.parameters(): p.data.normal_(0, 0.01)\n",
    "    loss_plot = []\n",
    "    epochs_reached = train_model(model, train_input, train_target, loss_plot, nb_epochs, batch_size = batch_size, lr = lr)\n",
    "    \n",
    "    train_error.append(compute_nb_errors(model, train_input, train_target, 10) / train_input.size(0) * 100)\n",
    "    validation_error.append(compute_nb_errors(model, validation_set_input, validation_set_target, 16) / validation_set_input.size(0) * 100)\n",
    "    test_error.append(compute_nb_errors(model, test_input, test_target, 50) / test_input.size(0) * 100)\n",
    "  \n",
    "    print('train_error {:.02f}% validation_set_error {:.02f}% test_error {:.02f}%'.format(train_error[i], validation_error[i], test_error[i]))\n",
    "    #loss_plot\n",
    "    for p in model.parameters(): p.data.normal_(0, 0.01)\n",
    "    plt.plot(range(epochs_reached+1),loss_plot)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    print('train_error AVG {:.02f}% validation_set_error AVG {:.02f}% test_error AVG {:.02f}%'.format(\n",
    "        numpy.asarray(train_error).mean(), \n",
    "        numpy.asarray(validation_error).mean(), \n",
    "        numpy.asarray(test_error).mean()))\n",
    "    print('train_error BEST {:.02f}% validation_set_error BEST {:.02f}% test_error BEST {:.02f}%\\n\\n\\n'.format(\n",
    "        numpy.asarray(train_error).min(), \n",
    "        numpy.asarray(validation_error).min(), \n",
    "        numpy.asarray(test_error).min()))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test multiple prior init\n",
    "\n",
    "# Select you model here!!!\n",
    "#||||||||||||||||||||||||\n",
    "#VVVVVVVVVVVVVVVVVVVVVVVV\n",
    "\n",
    "model = Net_basic(150)\n",
    "\n",
    "\n",
    "nb_epochs =  100\n",
    "batch_size = 50\n",
    "\n",
    "lr = 1e-4\n",
    "\n",
    "\n",
    "nb_training = 20\n",
    "\n",
    "train_error = []\n",
    "validation_error = []\n",
    "test_error = []\n",
    "\n",
    "for i in range(0,nb_training):\n",
    "    for p in model.parameters(): p.data.normal_(0, 0.01)\n",
    "    loss_plot = []\n",
    "    epochs_reached = train_model(model, train_input, train_target, loss_plot, nb_epochs, batch_size = batch_size, lr = lr)\n",
    "    \n",
    "    train_error.append(compute_nb_errors(model, train_input, train_target, 10) / train_input.size(0) * 100)\n",
    "    validation_error.append(compute_nb_errors(model, validation_set_input, validation_set_target, 16) / validation_set_input.size(0) * 100)\n",
    "    test_error.append(compute_nb_errors(model, test_input, test_target, 50) / test_input.size(0) * 100)\n",
    "  \n",
    "    print('train_error {:.02f}% validation_set_error {:.02f}% test_error {:.02f}%'.format(train_error[i], validation_error[i], test_error[i]))\n",
    "    #loss_plot\n",
    "    for p in model.parameters(): p.data.normal_(0, 0.01)\n",
    "    plt.plot(range(epochs_reached+1),loss_plot)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    print('train_error AVG {:.02f}% validation_set_error AVG {:.02f}% test_error AVG {:.02f}%'.format(\n",
    "        numpy.asarray(train_error).mean(), \n",
    "        numpy.asarray(validation_error).mean(), \n",
    "        numpy.asarray(test_error).mean()))\n",
    "    print('train_error BEST {:.02f}% validation_set_error BEST {:.02f}% test_error BEST {:.02f}%\\n\\n\\n'.format(\n",
    "        numpy.asarray(train_error).min(), \n",
    "        numpy.asarray(validation_error).min(), \n",
    "        numpy.asarray(test_error).min()))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test multiple prior init\n",
    "\n",
    "# Select you model here!!!\n",
    "#||||||||||||||||||||||||\n",
    "#VVVVVVVVVVVVVVVVVVVVVVVV\n",
    "\n",
    "model = Net_convnet(150)\n",
    "\n",
    "\n",
    "nb_epochs =  100\n",
    "batch_size = 50\n",
    "\n",
    "lr = 1e-4\n",
    "\n",
    "\n",
    "nb_training = 20\n",
    "\n",
    "train_error = []\n",
    "validation_error = []\n",
    "test_error = []\n",
    "\n",
    "for i in range(0,nb_training):\n",
    "    for p in model.parameters(): p.data.normal_(0, 0.01)\n",
    "    loss_plot = []\n",
    "    epochs_reached = train_model(model, train_input, train_target, loss_plot, nb_epochs, batch_size = batch_size, lr = lr)\n",
    "    \n",
    "    train_error.append(compute_nb_errors(model, train_input, train_target, 10) / train_input.size(0) * 100)\n",
    "    validation_error.append(compute_nb_errors(model, validation_set_input, validation_set_target, 16) / validation_set_input.size(0) * 100)\n",
    "    test_error.append(compute_nb_errors(model, test_input, test_target, 50) / test_input.size(0) * 100)\n",
    "  \n",
    "    print('train_error {:.02f}% validation_set_error {:.02f}% test_error {:.02f}%'.format(train_error[i], validation_error[i], test_error[i]))\n",
    "    #loss_plot\n",
    "    for p in model.parameters(): p.data.normal_(0, 0.01)\n",
    "    plt.plot(range(epochs_reached+1),loss_plot)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    print('train_error AVG {:.02f}% validation_set_error AVG {:.02f}% test_error AVG {:.02f}%'.format(\n",
    "        numpy.asarray(train_error).mean(), \n",
    "        numpy.asarray(validation_error).mean(), \n",
    "        numpy.asarray(test_error).mean()))\n",
    "    print('train_error BEST {:.02f}% validation_set_error BEST {:.02f}% test_error BEST {:.02f}%\\n\\n\\n'.format(\n",
    "        numpy.asarray(train_error).min(), \n",
    "        numpy.asarray(validation_error).min(), \n",
    "        numpy.asarray(test_error).min()))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test multiple prior init\n",
    "\n",
    "# Select you model here!!!\n",
    "#||||||||||||||||||||||||\n",
    "#VVVVVVVVVVVVVVVVVVVVVVVV\n",
    "\n",
    "model = Net_convnet_dropout(150)\n",
    "\n",
    "\n",
    "nb_epochs =  100\n",
    "batch_size = 50\n",
    "\n",
    "lr = 1e-4\n",
    "\n",
    "\n",
    "nb_training = 20\n",
    "\n",
    "train_error = []\n",
    "validation_error = []\n",
    "test_error = []\n",
    "\n",
    "for i in range(0,nb_training):\n",
    "    for p in model.parameters(): p.data.normal_(0, 0.01)\n",
    "    loss_plot = []\n",
    "    epochs_reached = train_model(model, train_input, train_target, loss_plot, nb_epochs, batch_size = batch_size, lr = lr)\n",
    "    \n",
    "    train_error.append(compute_nb_errors(model, train_input, train_target, 10) / train_input.size(0) * 100)\n",
    "    validation_error.append(compute_nb_errors(model, validation_set_input, validation_set_target, 16) / validation_set_input.size(0) * 100)\n",
    "    test_error.append(compute_nb_errors(model, test_input, test_target, 50) / test_input.size(0) * 100)\n",
    "  \n",
    "    print('train_error {:.02f}% validation_set_error {:.02f}% test_error {:.02f}%'.format(train_error[i], validation_error[i], test_error[i]))\n",
    "    #loss_plot\n",
    "    for p in model.parameters(): p.data.normal_(0, 0.01)\n",
    "    plt.plot(range(epochs_reached+1),loss_plot)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    print('train_error AVG {:.02f}% validation_set_error AVG {:.02f}% test_error AVG {:.02f}%'.format(\n",
    "        numpy.asarray(train_error).mean(), \n",
    "        numpy.asarray(validation_error).mean(), \n",
    "        numpy.asarray(test_error).mean()))\n",
    "    print('train_error BEST {:.02f}% validation_set_error BEST {:.02f}% test_error BEST {:.02f}%\\n\\n\\n'.format(\n",
    "        numpy.asarray(train_error).min(), \n",
    "        numpy.asarray(validation_error).min(), \n",
    "        numpy.asarray(test_error).min()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
