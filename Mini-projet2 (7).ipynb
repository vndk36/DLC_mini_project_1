{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import FloatTensor\n",
    "\n",
    "NAME_INDEX = 0\n",
    "DATA_INDEX = 1\n",
    "GRAD_INDEX = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_disc_set(nb):\n",
    "    # Generates data and corresponding target\n",
    "    \n",
    "    input = FloatTensor(nb, 2).uniform_(0, 1)\n",
    "    target = torch.norm(input, 2, 1) < math.sqrt(1/(2*math.pi))\n",
    "    return input, target.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameter():\n",
    "    # class used to create all the parameters in the same way\n",
    "    \n",
    "    def __init__(self, name, tensor, gradient):\n",
    "        self.name = name       # name of the parameter\n",
    "        self.data = tensor     # parameter values\n",
    "        self.grad = gradient   # gradient of the parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module ( Parameter ) :\n",
    "    # base module that the following class inherits\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Parameter, self).__init__()\n",
    "        self.name = 'Base Module'  # name of the module\n",
    "        self.param = []            # contains all the parameters of the Module\n",
    "        \n",
    "    def forward (self, * input) :\n",
    "        # Computes the forward pass of the Module.\n",
    "        # Need to be implemented in future class if one wants to use it.\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backward (self , * gradwrtoutput) :\n",
    "        # Computes the backward pass of the Module for the backpropagation of the loss.\n",
    "        # Need to be implemented in future class if one wants to use it.\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def init_parameters ( self ):\n",
    "        # Initialize the proper parameters for the Module.\n",
    "        # Need to be implemented in future class if one wants to use it.\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def add_parameter(self, parameter):\n",
    "        # Adds the input parameter to the already existing parameters of the Module.\n",
    "        # Different implementation if the input parameter is:\n",
    "            # - an object of class 'Parameter'(when you initialize parameters in the current module)\n",
    "            # - a list of objects(when you add all the parameters of a module to another one)\n",
    "        if parameter.__class__.__name__ == 'Parameter':\n",
    "            self.param.append((parameter.name, parameter.data, parameter.grad))\n",
    "        elif parameter.__class__.__name__ == 'list':                        \n",
    "            if parameter != []:\n",
    "                self.param.append(parameter)\n",
    "                    \n",
    "    def zero_grad( self ):\n",
    "        # Reset the gradient of the parameters to 0\n",
    "        for i in range(len(self.param)):            # loop on the different Module initialized in the 'self' Module\n",
    "            for j in range(len(self.param[i])):     # loop on the parameters of each Module\n",
    "                self.param[i][j][GRAD_INDEX][:] = 0\n",
    "                    \n",
    "    def optimizer (self, lr = 1e-5):\n",
    "        # Stochastic Gradient descent\n",
    "        # updates the parameters in regard of their gradient and the input learning rate\n",
    "        for i in range(len(self.param)):           # loop on the different Module initialized in the 'self' Module\n",
    "            for j in range(len(self.param[i])):    # loop on the parameters of each Module\n",
    "                self.param[i][j][DATA_INDEX][:] -= lr * self.param[i][j][GRAD_INDEX][:]\n",
    "                \n",
    "    def parameters ( self ):\n",
    "        # returns the all parameters of the Module\n",
    "        return self.param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSEloss( Module ):\n",
    "    # Compute the Mean Square Error between the given input and target\n",
    "    # no parameters needed\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MSEloss, self).__init__()\n",
    "        \n",
    "    def forward (self, input, target):\n",
    "        return input.sub(target.view(-1, 1)).pow(2).sum() \n",
    "    \n",
    "    def backward (self, input, target):\n",
    "        return 2*(input.sub(target.view(-1, 1)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU( Module ):\n",
    "    # Activation functions: Rectified Linear Unit on each element of the input\n",
    "    # no parameters needed\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ReLU, self).__init__()\n",
    "        self.name = 'ReLU'\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return input.clamp(min = 0)\n",
    "    \n",
    "    def backward(self, input, dx):\n",
    "        input[input <= 0] = 0\n",
    "        input[input > 0] = 1\n",
    "        return input * dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module Tanh\n",
    "\n",
    "class Tanh( Module ):\n",
    "    # Activation functions: Hyperbolic tangent of each element of the input\n",
    "    # no parameters needed\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Tanh, self).__init__()\n",
    "        self.name = 'Tanh'\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return input.tanh()\n",
    "    \n",
    "    def backward(self, input, dx):\n",
    "        return 4 * (input.exp() + input.mul(-1).exp()).pow(-2) * dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear( Module ):\n",
    "    # Linear transformation with certain weights and bias\n",
    "    \n",
    "    Linear_counter = 0 # counter of the number of Linear module created in order to name properly the parameters\n",
    "    \n",
    "    def __init__(self, input_features, output_features, eps = 1e-2):\n",
    "        super(Linear, self).__init__()\n",
    "        self.name = 'Linear'\n",
    "        Linear.Linear_counter += 1        \n",
    "        self.init_parameters(input_features, output_features, eps)\n",
    "        \n",
    "    def init_parameters (self, input_features, output_features, eps):\n",
    "        # initializes the weight parameters with a normal distribution and set their gradient to 0\n",
    "        weigths_name = f'weights{self.Linear_counter}'\n",
    "        self.weights = Parameter(weigths_name, torch.Tensor(input_features, output_features),\n",
    "                                 torch.Tensor(input_features, output_features))\n",
    "        self.weights.data.normal_(0, eps)\n",
    "        self.weights.grad.zero_()\n",
    "        \n",
    "        # initializes the bias parameters with a normal distribution and set their gradient to 0\n",
    "        bias_name = f'bias{self.Linear_counter}'\n",
    "        self.bias = Parameter(bias_name, torch.Tensor(output_features), torch.Tensor(output_features))  \n",
    "        self.bias.data.normal_(0, eps)\n",
    "        self.bias.grad.zero_()\n",
    "        \n",
    "        # adds the weight and bias parameters to this Module\n",
    "        self.add_parameter(self.weights)\n",
    "        self.add_parameter(self.bias)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = input.mm(self.weights.data)\n",
    "        output += self.bias.data\n",
    "        return output\n",
    "    \n",
    "    def backward(self, input, ds):\n",
    "        dx = ds.mm(self.weights.data.t())\n",
    "        dw = input.t().mm(ds)\n",
    "        db = ds.t().mm(torch.ones(ds.size(0), 1))\n",
    "        \n",
    "        self.weights.grad.add_(dw) # updates the gradient of the parameters with the computed value\n",
    "        self.bias.grad.add_(db)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential( Module ):\n",
    "    # Sequential container of Modules object.\n",
    "    # The order is given by the user when creating the object of class Sequential\n",
    "    \n",
    "    def __init__(self, *args):\n",
    "        super(Sequential, self).__init__()\n",
    "        Linear.Linear_counter = 0               # resets the number of Linear for each sequential object\n",
    "        self.module_nb = len(args)\n",
    "        self.fc = [None] * self.module_nb       # contains the modules object in order\n",
    "        self.x = [None] * (self.module_nb + 1)  # contains the input of the model \n",
    "                                                # and the intermediate results after the forward pass of each module \n",
    "        \n",
    "        for id, module in enumerate(args):      # fills the list containing the modules and adds their parameters to\n",
    "            self.fc[id] = module                # the sequential 'self' module\n",
    "            self.init_parameters(id)\n",
    "        \n",
    "    def init_parameters (self, id):\n",
    "        self.add_parameter(self.fc[id].parameters())\n",
    "        \n",
    "    def forward(self, input):                   # execute the forward pass of each module in the order given by the user\n",
    "        self.x[0] = input                       # fills the list with the intermediate output of the forward\n",
    "                                                # pass of each module \n",
    "        for i in range(1, self.module_nb + 1):  \n",
    "            self.x[i] = self.fc[i-1].forward(self.x[i-1])\n",
    "        return self.x[self.module_nb]\n",
    "    \n",
    "    def backward(self, dloss):                  # execute the backward pass of each module in the inverse order\n",
    "        dx = [None] * (self.module_nb + 1)      # compared to the forward pass\n",
    "        dx[self.module_nb] = dloss\n",
    "        \n",
    "        for i in range(1, self.module_nb + 1):\n",
    "            j = self.module_nb - i\n",
    "            dx[j] = self.fc[j].backward(self.x[j], dx[j+1])\n",
    "            \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Net 4 layers\n",
    "\n",
    "Linear.Linear_counter = 0\n",
    "\n",
    "class Net4( Module ):\n",
    "    def __init__(self, hidden_layer):\n",
    "        super(Net4, self).__init__()\n",
    "        self.fc1 = Linear(2, 2*hidden_layer)\n",
    "        self.fc2 = ReLU()\n",
    "        self.fc3 = Linear(2*hidden_layer, hidden_layer)\n",
    "        self.fc4 = Linear(hidden_layer, 1)\n",
    "        self.init_parameters()\n",
    "        \n",
    "    def init_parameters ( self ):\n",
    "        self.add_parameter( self.fc1.parameters() )\n",
    "        self.add_parameter( self.fc2.parameters() )\n",
    "        self.add_parameter( self.fc3.parameters() )\n",
    "        self.add_parameter( self.fc4.parameters() )\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x0 = x\n",
    "        x = self.fc1.forward( x )\n",
    "        self.s1 = x\n",
    "        x = self.fc2.forward( x )\n",
    "        self.x1 = x\n",
    "        x = self.fc3.forward( x )\n",
    "        self.s2 = x\n",
    "        x = self.fc2.forward( x )\n",
    "        self.x2 = x\n",
    "        x = self.fc4.forward( x )\n",
    "        self.s3 = x\n",
    "        x = self.fc2.forward( x )\n",
    "        self.x3 = x\n",
    "        return x\n",
    "    \n",
    "    def backward(self, dloss):\n",
    "        dx3 = dloss\n",
    "        ds3 = self.fc2.backward(self.s3) * dx3\n",
    "        dx2, dw4, db4 = self.fc4.backward( ds3, self.x2 )\n",
    "        self.fc4.weights.grad.add_(dw4)\n",
    "        self.fc4.bias.grad.add_(db4)\n",
    "        ds2 = self.fc2.backward(self.s2) * dx2\n",
    "        dx1, dw3, db3 = self.fc3.backward( ds2 , self.x1 )\n",
    "        self.fc3.weights.grad.add_(dw3)\n",
    "        self.fc3.bias.grad.add_(db3)\n",
    "        \n",
    "        ds1 = self.fc2.backward(self.s1) * dx1\n",
    "        \n",
    "        dx0, dw1, db1 = self.fc1.backward( ds1 , self.x0 )\n",
    "\n",
    "        self.fc1.weights.grad.add_(dw1)\n",
    "        self.fc1.bias.grad.add_(db1)\n",
    "        \n",
    "        return dx0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, train_input, train_target, mini_batch_size = 100, lr = 1e-1, nb_epochs = 250):\n",
    "    # trains the given model 'nb_epochs' times and prints the loss for each iteration in the end\n",
    "    \n",
    "    sum_loss = FloatTensor(nb_epochs).zero_()                     # contains the loss after each iteration\n",
    "    \n",
    "    for e in range(0, nb_epochs):\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):  # divides the input data into batches\n",
    "            # input go through the model\n",
    "            output = model.forward(train_input.narrow(0, b, mini_batch_size))\n",
    "            \n",
    "            # loss and dloss computation to train the model and visualize it\n",
    "            loss = criterion.forward(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            sum_loss[e] += loss\n",
    "            dloss = criterion.backward(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            \n",
    "            # reset the gradient before the backpropagation of the loss by gradient descent\n",
    "            # in order to update the parameters (learning phase)\n",
    "            model.zero_grad()\n",
    "            model.backward(dloss)\n",
    "            model.optimizer(lr)\n",
    "            \n",
    "        print(e, sum_loss[e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, data_input, data_target, mini_batch_size = 100):\n",
    "    # computes the number of datapoint wrongly classified by the model\n",
    "    \n",
    "    total_nb_errors = 0\n",
    "    \n",
    "    for b in range(0, data_input.size(0), mini_batch_size):\n",
    "        \n",
    "        output = model.forward(data_input.narrow(0, b, mini_batch_size))   # the predicted class is the column of the output with the greater value\n",
    "        print(output)\n",
    "        _, predicted_classes = torch.max(output, 1)                        # the predicted class \n",
    "        print(predicted_classes)\n",
    "        \n",
    "        for k in range(0, mini_batch_size): \n",
    "            if data_target[b + k] != predicted_classes[k]:\n",
    "                total_nb_errors += 1\n",
    "\n",
    "    return total_nb_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dave/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: other is not broadcastable to self, but they have the same number of elements.  Falling back to deprecated pointwise behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5205.5048828125\n",
      "1 431.0277099609375\n",
      "2 311.7295837402344\n",
      "3 279.97479248046875\n",
      "4 268.1896667480469\n",
      "5 262.77606201171875\n",
      "6 259.81573486328125\n",
      "7 258.03985595703125\n",
      "8 256.9345703125\n",
      "9 256.22821044921875\n",
      "10 255.76443481445312\n",
      "11 255.44952392578125\n",
      "12 255.2233428955078\n",
      "13 255.04905700683594\n",
      "14 254.910400390625\n",
      "15 254.79998779296875\n",
      "16 254.7117919921875\n",
      "17 254.63804626464844\n",
      "18 254.57318115234375\n",
      "19 254.51605224609375\n",
      "20 254.46571350097656\n",
      "21 254.42140197753906\n",
      "22 254.38233947753906\n",
      "23 254.3479461669922\n",
      "24 254.31764221191406\n",
      "25 254.29095458984375\n",
      "26 254.26744079589844\n",
      "27 254.2467498779297\n",
      "28 254.22850036621094\n",
      "29 254.21243286132812\n",
      "30 254.19827270507812\n",
      "31 254.185791015625\n",
      "32 254.1748046875\n",
      "33 254.16513061523438\n",
      "34 254.1564483642578\n",
      "35 254.14852905273438\n",
      "36 254.1413116455078\n",
      "37 254.1347198486328\n",
      "38 254.12857055664062\n",
      "39 254.1227569580078\n",
      "40 254.1173095703125\n",
      "41 254.1121826171875\n",
      "42 254.1073760986328\n",
      "43 254.10284423828125\n",
      "44 254.0985870361328\n",
      "45 254.09457397460938\n",
      "46 254.0908203125\n",
      "47 254.0872802734375\n",
      "48 254.08395385742188\n",
      "49 254.080810546875\n",
      "50 254.07786560058594\n",
      "51 254.0751190185547\n",
      "52 254.072509765625\n",
      "53 254.070068359375\n",
      "54 254.06776428222656\n",
      "55 254.0655975341797\n",
      "56 254.0635528564453\n",
      "57 254.06155395507812\n",
      "58 254.0596160888672\n",
      "59 254.05775451660156\n",
      "60 254.05593872070312\n",
      "61 254.05418395996094\n",
      "62 254.052490234375\n",
      "63 254.05084228515625\n",
      "64 254.0492401123047\n",
      "65 254.04769897460938\n",
      "66 254.04620361328125\n",
      "67 254.0447540283203\n",
      "68 254.04335021972656\n",
      "69 254.0419921875\n",
      "70 254.04067993164062\n",
      "71 254.03939819335938\n",
      "72 254.0381622314453\n",
      "73 254.03695678710938\n",
      "74 254.0358123779297\n",
      "75 254.03468322753906\n",
      "76 254.03359985351562\n",
      "77 254.0325469970703\n",
      "78 254.03152465820312\n",
      "79 254.03053283691406\n",
      "80 254.02957153320312\n",
      "81 254.0286407470703\n",
      "82 254.02774047851562\n",
      "83 254.02687072753906\n",
      "84 254.02603149414062\n",
      "85 254.0252227783203\n",
      "86 254.02442932128906\n",
      "87 254.02366638183594\n",
      "88 254.02291870117188\n",
      "89 254.02220153808594\n",
      "90 254.02149963378906\n",
      "91 254.0208282470703\n",
      "92 254.02017211914062\n",
      "93 254.01954650878906\n",
      "94 254.01893615722656\n",
      "95 254.01834106445312\n",
      "96 254.01776123046875\n",
      "97 254.01719665527344\n",
      "98 254.01666259765625\n",
      "99 254.01614379882812\n",
      "100 254.01564025878906\n",
      "101 254.01515197753906\n",
      "102 254.01466369628906\n",
      "103 254.0142059326172\n",
      "104 254.01376342773438\n",
      "105 254.01333618164062\n",
      "106 254.01290893554688\n",
      "107 254.01251220703125\n",
      "108 254.01211547851562\n",
      "109 254.01173400878906\n",
      "110 254.01136779785156\n",
      "111 254.01101684570312\n",
      "112 254.0106658935547\n",
      "113 254.0103302001953\n",
      "114 254.010009765625\n",
      "115 254.0096893310547\n",
      "116 254.00938415527344\n",
      "117 254.00909423828125\n",
      "118 254.00880432128906\n",
      "119 254.00852966308594\n",
      "120 254.00827026367188\n",
      "121 254.0080108642578\n",
      "122 254.00775146484375\n",
      "123 254.00750732421875\n",
      "124 254.0072784423828\n",
      "125 254.00704956054688\n",
      "126 254.0068359375\n",
      "127 254.00660705566406\n",
      "128 254.00640869140625\n",
      "129 254.00621032714844\n",
      "130 254.00601196289062\n",
      "131 254.00582885742188\n",
      "132 254.00564575195312\n",
      "133 254.00546264648438\n",
      "134 254.0052947998047\n",
      "135 254.005126953125\n",
      "136 254.0049591064453\n",
      "137 254.0048065185547\n",
      "138 254.00465393066406\n",
      "139 254.0045166015625\n",
      "140 254.00436401367188\n",
      "141 254.0042266845703\n",
      "142 254.0041046142578\n",
      "143 254.00396728515625\n",
      "144 254.00384521484375\n",
      "145 254.00372314453125\n",
      "146 254.0036163330078\n",
      "147 254.0034942626953\n",
      "148 254.00338745117188\n",
      "149 254.00328063964844\n",
      "150 254.003173828125\n",
      "151 254.00308227539062\n",
      "152 254.0029754638672\n",
      "153 254.0028839111328\n",
      "154 254.00279235839844\n",
      "155 254.00271606445312\n",
      "156 254.00262451171875\n",
      "157 254.00254821777344\n",
      "158 254.00245666503906\n",
      "159 254.00238037109375\n",
      "160 254.00230407714844\n",
      "161 254.0022430419922\n",
      "162 254.00216674804688\n",
      "163 254.00210571289062\n",
      "164 254.0020294189453\n",
      "165 254.00196838378906\n",
      "166 254.0019073486328\n",
      "167 254.00184631347656\n",
      "168 254.0017852783203\n",
      "169 254.00173950195312\n",
      "170 254.00167846679688\n",
      "171 254.0016326904297\n",
      "172 254.00157165527344\n",
      "173 254.00152587890625\n",
      "174 254.00148010253906\n",
      "175 254.00143432617188\n",
      "176 254.0013885498047\n",
      "177 254.0013427734375\n",
      "178 254.0012969970703\n",
      "179 254.0012664794922\n",
      "180 254.001220703125\n",
      "181 254.00119018554688\n",
      "182 254.0011444091797\n",
      "183 254.00111389160156\n",
      "184 254.00106811523438\n",
      "185 254.00103759765625\n",
      "186 254.00100708007812\n",
      "187 254.0009765625\n",
      "188 254.00094604492188\n",
      "189 254.00091552734375\n",
      "190 254.00088500976562\n",
      "191 254.0008544921875\n",
      "192 254.00083923339844\n",
      "193 254.0008087158203\n",
      "194 254.0007781982422\n",
      "195 254.00076293945312\n",
      "196 254.000732421875\n",
      "197 254.00071716308594\n",
      "198 254.0006866455078\n",
      "199 254.00067138671875\n",
      "200 254.00064086914062\n",
      "201 254.00062561035156\n",
      "202 254.0006103515625\n",
      "203 254.00057983398438\n",
      "204 254.0005645751953\n",
      "205 254.00054931640625\n",
      "206 254.0005340576172\n",
      "207 254.00051879882812\n",
      "208 254.00050354003906\n",
      "209 254.00048828125\n",
      "210 254.00047302246094\n",
      "211 254.00045776367188\n",
      "212 254.0004425048828\n",
      "213 254.00042724609375\n",
      "214 254.0004119873047\n",
      "215 254.00039672851562\n",
      "216 254.00038146972656\n",
      "217 254.00038146972656\n",
      "218 254.0003662109375\n",
      "219 254.00035095214844\n",
      "220 254.00033569335938\n",
      "221 254.00033569335938\n",
      "222 254.0003204345703\n",
      "223 254.00030517578125\n",
      "224 254.00030517578125\n",
      "225 254.0002899169922\n",
      "226 254.00027465820312\n",
      "227 254.00027465820312\n",
      "228 254.00025939941406\n",
      "229 254.00025939941406\n",
      "230 254.000244140625\n",
      "231 254.000244140625\n",
      "232 254.00022888183594\n",
      "233 254.00022888183594\n",
      "234 254.00021362304688\n",
      "235 254.00021362304688\n",
      "236 254.0001983642578\n",
      "237 254.0001983642578\n",
      "238 254.0001983642578\n",
      "239 254.00018310546875\n",
      "240 254.00018310546875\n",
      "241 254.0001678466797\n",
      "242 254.0001678466797\n",
      "243 254.0001678466797\n",
      "244 254.00015258789062\n",
      "245 254.00015258789062\n",
      "246 254.00015258789062\n",
      "247 254.00013732910156\n",
      "248 254.00013732910156\n",
      "249 254.00013732910156\n",
      "\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "[torch.FloatTensor of size 100x2]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 100]\n",
      "\n",
      "\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "[torch.FloatTensor of size 100x2]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 100]\n",
      "\n",
      "\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "[torch.FloatTensor of size 100x2]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 100]\n",
      "\n",
      "\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "[torch.FloatTensor of size 100x2]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 100]\n",
      "\n",
      "\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "[torch.FloatTensor of size 100x2]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 100]\n",
      "\n",
      "\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "[torch.FloatTensor of size 100x2]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 100]\n",
      "\n",
      "\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "[torch.FloatTensor of size 100x2]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 100]\n",
      "\n",
      "\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "[torch.FloatTensor of size 100x2]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 100]\n",
      "\n",
      "\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "[torch.FloatTensor of size 100x2]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 100]\n",
      "\n",
      "\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "[torch.FloatTensor of size 100x2]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 100]\n",
      "\n",
      "\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "[torch.FloatTensor of size 100x2]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 100]\n",
      "\n",
      "\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "[torch.FloatTensor of size 100x2]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 100]\n",
      "\n",
      "\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "[torch.FloatTensor of size 100x2]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 100]\n",
      "\n",
      "\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "[torch.FloatTensor of size 100x2]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "[torch.FloatTensor of size 100x2]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 100]\n",
      "\n",
      "\n",
      "1.00000e-02 *\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  1.1462\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "  0.0000  0.0000\n",
      "[torch.FloatTensor of size 100x2]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 100]\n",
      "\n",
      "\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "[torch.FloatTensor of size 100x2]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 100]\n",
      "\n",
      "\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "[torch.FloatTensor of size 100x2]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 100]\n",
      "\n",
      "\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "[torch.FloatTensor of size 100x2]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 100]\n",
      "\n",
      "\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "    0     0\n",
      "[torch.FloatTensor of size 100x2]\n",
      "\n",
      "\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.LongTensor of size 100]\n",
      "\n",
      "118\n",
      "test error Net 11.80%% 118/1000\n",
      "train error Net 12.80%% 128/1000\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target = generate_disc_set(1000)\n",
    "test_input, test_target = generate_disc_set(1000)\n",
    "mean, std = train_input.mean(), train_input.std()\n",
    "train_input.sub_(mean).div_(std)\n",
    "test_input.sub_(mean).div_(std);\n",
    "\n",
    "mini_batch_size = 100\n",
    "nb_epochs = 250\n",
    "\n",
    "model = Sequential(Linear(2, 25, 1), ReLU(), Linear(25, 25, 1), ReLU(), Linear(25, 2, 1), ReLU())\n",
    "criterion = MSEloss()\n",
    "train_model(model, criterion, train_input, train_target, mini_batch_size, 1e-5, nb_epochs)\n",
    "nb_test_errors = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "nb_train_errors = compute_nb_errors(model, train_input, train_target, mini_batch_size)\n",
    "\n",
    "print(nb_test_errors)\n",
    "print('test error Net {:0.2f}%% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                      nb_test_errors, test_input.size(0)))\n",
    "print('train error Net {:0.2f}%% {:d}/{:d}'.format((100 * nb_train_errors) / train_input.size(0),\n",
    "                                                      nb_train_errors, train_input.size(0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type Variable[torch.LongTensor] but found type Variable[torch.ByteTensor] for argument #1 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-00870e50bf70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m print('std {:f} train_error {:.02f}% test_error {:.02f}%'.format(\n",
      "\u001b[0;32m<ipython-input-83-00870e50bf70>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_input, train_target)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnarrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m         return F.cross_entropy(input, target, self.weight, self.size_average,\n\u001b[0;32m--> 679\u001b[0;31m                                self.ignore_index, self.reduce)\n\u001b[0m\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \"\"\"\n\u001b[0;32m-> 1161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of type Variable[torch.LongTensor] but found type Variable[torch.ByteTensor] for argument #1 'target'"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "\n",
    "import torch\n",
    "import math\n",
    "\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def generate_disc_set(nb):\n",
    "    input = Tensor(nb, 2).uniform_(0, 1)\n",
    "    target = torch.norm(input, 2, 1) < math.sqrt(1/(2*math.pi))\n",
    "    return input, target\n",
    "\n",
    "train_input, train_target = generate_disc_set(1000)\n",
    "test_input, test_target = generate_disc_set(1000)\n",
    "\n",
    "mean, std = train_input.mean(), train_input.std()\n",
    "\n",
    "train_input.sub_(mean).div_(std)\n",
    "test_input.sub_(mean).div_(std)\n",
    "\n",
    "train_input, train_target = Variable(train_input), Variable(train_target)\n",
    "test_input, test_target = Variable(test_input), Variable(test_target)\n",
    "\n",
    "mini_batch_size = 100\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def train_model(model, train_input, train_target):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 1e-1)\n",
    "    nb_epochs = 250\n",
    "\n",
    "    for e in range(0, nb_epochs):\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def compute_nb_errors(model, data_input, data_target):\n",
    "\n",
    "    nb_data_errors = 0\n",
    "\n",
    "    for b in range(0, data_input.size(0), mini_batch_size):\n",
    "        output = model(data_input.narrow(0, b, mini_batch_size))\n",
    "        print(output)\n",
    "        _, predicted_classes = torch.max(output.data, 1)\n",
    "        for k in range(0, mini_batch_size):\n",
    "            if data_target.data[b + k] != predicted_classes[k]:\n",
    "                nb_data_errors = nb_data_errors + 1\n",
    "\n",
    "    return nb_data_errors\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def create_shallow_model():\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(2, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 2)\n",
    "    )\n",
    "\n",
    "######################################################################\n",
    "\n",
    "model = create_shallow_model()\n",
    "for p in model.parameters(): p.data.normal_(0, 1e-1)\n",
    "\n",
    "train_model(model, train_input, train_target)\n",
    "\n",
    "print('std {:f} train_error {:.02f}% test_error {:.02f}%'.format(\n",
    "        std,\n",
    "        compute_nb_errors(model, train_input, train_target) / train_input.size(0) * 100,\n",
    "        compute_nb_errors(model, test_input, test_target) / test_input.size(0) * 100\n",
    "    )\n",
    "    )\n",
    "\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
