{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBERS = '0123456789' \n",
    "def increment(s): # function taken from here:\n",
    "    out = ''      # https://codegolf.stackexchange.com/questions/38033/increment-every-number-in-a-string\n",
    "\n",
    "    number = ''\n",
    "    for c in s:\n",
    "        if c in NUMBERS:\n",
    "            number += c\n",
    "        else:\n",
    "            if number != '':\n",
    "                out += str(int(number) + 1)\n",
    "                number = ''\n",
    "            out += c\n",
    "\n",
    "    if number != '':\n",
    "        out += str(int(number) + 1)\n",
    "        number = ''\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_disc_set(nb):\n",
    "    input = FloatTensor(nb, 2).uniform_(0, 1)\n",
    "    target = torch.norm(input,2,1) < math.sqrt(1/(2*math.pi))\n",
    "    return input, target.float()\n",
    "\n",
    "train_input, train_target = generate_disc_set(1000)\n",
    "test_input, test_target = generate_disc_set(1000)\n",
    "\n",
    "mean, std = train_input.mean(), train_input.std()\n",
    "\n",
    "train_input.sub_(mean).div_(std)\n",
    "test_input.sub_(mean).div_(std);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Parameter\n",
    "\n",
    "class Parameter():\n",
    "    def __init__(self, name, tensor, gradient):\n",
    "        self.name = name\n",
    "        self.data = tensor\n",
    "        self.grad = gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple structure for a Module\n",
    "\n",
    "class Module ( Parameter ) :\n",
    "    def __init__(self):\n",
    "        super(Parameter, self).__init__()\n",
    "        self.param = []\n",
    "        \n",
    "    def forward ( self , * input ) :\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backward ( self , * gradwrtoutput ) :\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def init_parameters ( self ):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def add_parameter( self , parameter ):\n",
    "        if parameter.__class__.__name__ == 'Parameter':\n",
    "            self.param.append((parameter.name, parameter.data, parameter.grad))\n",
    "        else:\n",
    "            if parameter.__class__.__name__ == 'list':                        \n",
    "                if parameter != []:\n",
    "                    self.param.append(parameter)\n",
    "                    \n",
    "    def zero_grad( self ):\n",
    "        for i in range(len(self.param)):\n",
    "            for j in range(len(self.param[i])):\n",
    "                self.param[i][j][2][:] = 0\n",
    "                \n",
    "    def update_one_parameter( self, name, new_param, new_grad):\n",
    "        for i in range(len(self.param)):\n",
    "            for j in range(len(self.param[i])):\n",
    "                if self.param[i][j][0] == name:\n",
    "                    self.param[i][j][1] = new_param\n",
    "                    self.param[i][j][2] = new_grad\n",
    "                    \n",
    "    def update_all_parameters( self ):\n",
    "        raise NotImplementedError\n",
    "    def parameters ( self ):\n",
    "        return self.param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module for MSEloss\n",
    "\n",
    "class MSEloss( Module ):\n",
    "    def __init__(self):\n",
    "        super(MSEloss, self).__init__()\n",
    "    def forward ( self , input, target ):\n",
    "        return input.sub(target).pow(2).sum()    \n",
    "    def backward ( self , input, target ):\n",
    "        return 2*(input.sub(target))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module ReLU\n",
    "\n",
    "class ReLU( Module ):\n",
    "    def __init__(self):\n",
    "        super(ReLU, self).__init__()\n",
    "    def forward( self, input ):\n",
    "        return input.clamp(min = 0)\n",
    "    def backward( self, input ):\n",
    "        input[input <= 0] = 0\n",
    "        input[input > 0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module Tanh\n",
    "\n",
    "class Tanh( Module ):\n",
    "    def __init__(self):\n",
    "        super(Tanh, self).__init__()\n",
    "    def forward( self , input ):\n",
    "        return input.tanh()\n",
    "    def backward( self, input ):\n",
    "        return 4 * (input.exp() + input.mul(-1).exp()).pow(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test module linear\n",
    "\n",
    "class Linear( Module ):\n",
    "    \n",
    "    Linear_counter = 0\n",
    "    \n",
    "    def __init__(self, input_features, output_features, eps=1e-6):\n",
    "        super(Linear, self).__init__()\n",
    "        self.input_features = input_features\n",
    "        self.output_features = output_features\n",
    "        self.init_parameters(input_features, output_features, eps)\n",
    "        Linear.Linear_counter +=1\n",
    "        \n",
    "    def init_parameters ( self, input_features, output_features, eps ):\n",
    "        weigths_name = 'weights0'\n",
    "        bias_name = 'bias0'\n",
    "        for i in range(self.Linear_counter):\n",
    "            weigths_name = increment(weigths_name)\n",
    "            bias_name = increment(bias_name)\n",
    "        self.weights = Parameter(weigths_name, torch.Tensor(output_features, input_features),\n",
    "                                 torch.Tensor(output_features, input_features))\n",
    "        self.bias = Parameter(bias_name, torch.Tensor(output_features), torch.Tensor(output_features))\n",
    "        self.weights.data.normal_(0, eps)\n",
    "        self.weights.grad.zero_()\n",
    "        self.bias.grad.zero_()\n",
    "        self.bias.data.normal_(0, eps)\n",
    "        self.add_parameter(self.weights)\n",
    "        self.add_parameter(self.bias)\n",
    "        \n",
    "    def forward( self , input):\n",
    "        output = input.matmul(self.weights.data.t())\n",
    "        output += self.bias.data\n",
    "        return output\n",
    "    \n",
    "    def backward( self, dloss ):\n",
    "        print(self.weights.data.t())\n",
    "        return self.weights.data.t().mm(dloss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.00000e-06 *\n",
      " -0.2179\n",
      "  0.1015\n",
      " -0.8712\n",
      " -0.7506\n",
      "  1.3573\n",
      " -1.3706\n",
      " -0.7605\n",
      "  0.5757\n",
      " -0.9414\n",
      " -0.6347\n",
      " -0.8749\n",
      "  0.6937\n",
      "  0.9265\n",
      "  1.1002\n",
      "  0.8966\n",
      "  2.9314\n",
      " -0.0430\n",
      "  0.2860\n",
      "  1.5812\n",
      " -0.0351\n",
      "  0.5213\n",
      " -0.0412\n",
      " -0.1651\n",
      "  1.5628\n",
      " -0.5410\n",
      " -0.1206\n",
      "  1.6604\n",
      "  0.7558\n",
      " -0.1113\n",
      "  2.0788\n",
      "  1.4717\n",
      " -0.0513\n",
      "  1.1417\n",
      " -1.8669\n",
      "  0.1443\n",
      " -1.9956\n",
      "  1.5940\n",
      "  0.7869\n",
      " -1.3360\n",
      " -0.4191\n",
      " -0.5242\n",
      " -0.0867\n",
      "  0.4952\n",
      " -1.0829\n",
      "  1.2301\n",
      " -0.0039\n",
      "  0.9629\n",
      " -1.0122\n",
      "  0.3068\n",
      " -0.1220\n",
      " -0.9768\n",
      " -0.2973\n",
      " -0.5266\n",
      " -1.3116\n",
      "  0.0949\n",
      "  0.2603\n",
      " -1.3233\n",
      "  1.2372\n",
      "  1.4665\n",
      " -0.5633\n",
      " -1.0312\n",
      "  1.5584\n",
      "  0.2656\n",
      "  0.1050\n",
      "  0.8880\n",
      " -1.9023\n",
      " -0.1157\n",
      " -1.5434\n",
      " -0.3487\n",
      "  1.6651\n",
      " -0.1621\n",
      "  1.3767\n",
      "  2.5949\n",
      "  1.2992\n",
      " -0.0164\n",
      "  0.9533\n",
      "  1.1453\n",
      " -1.2265\n",
      "  0.9878\n",
      "  0.1553\n",
      " -0.1385\n",
      "  0.1965\n",
      " -0.5476\n",
      " -1.1106\n",
      "  0.4544\n",
      "  1.0028\n",
      "  1.9383\n",
      "  1.0289\n",
      "  0.8282\n",
      "  0.3816\n",
      " -0.3557\n",
      " -1.8828\n",
      " -0.1062\n",
      "  1.3086\n",
      "  1.7038\n",
      " -0.0842\n",
      "  0.7337\n",
      "  0.0570\n",
      " -1.2351\n",
      "  0.0591\n",
      "[torch.FloatTensor of size 100x1]\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [100 x 1], m2: [1000 x 1000] at /opt/conda/conda-bld/pytorch_1518243271935/work/torch/lib/TH/generic/THTensorMath.c:1434",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-459-2a8101b5256b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mdloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mdl_dwfc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_dbfc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_dwfc3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_dbfc3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-459-2a8101b5256b>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dloss)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdl_dx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mdl_ds2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdl_dx2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mdl_dx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_ds2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mdl_ds1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdl_dx1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-458-6e9686ebaca8>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dloss)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdloss\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [100 x 1], m2: [1000 x 1000] at /opt/conda/conda-bld/pytorch_1518243271935/work/torch/lib/TH/generic/THTensorMath.c:1434"
     ]
    }
   ],
   "source": [
    "# test Net\n",
    "\n",
    "Linear.Linear_counter = 0\n",
    "\n",
    "class Net( Module ):\n",
    "    def __init__(self, hidden_layer):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = Linear(2, hidden_layer)\n",
    "        self.fc2 = Tanh()\n",
    "        self.fc3 = Linear(hidden_layer, 1)\n",
    "        self.add_parameter( self.fc1.parameters() )\n",
    "        self.add_parameter( self.fc2.parameters() )\n",
    "        self.add_parameter( self.fc3.parameters() )\n",
    "        \n",
    "        self.x0 = 0\n",
    "        self.s1 = 0\n",
    "        self.x1 = 0\n",
    "        self.s2 = 0\n",
    "        self.x2 = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x0 = x\n",
    "        self.s1 = self.fc1.forward( self.x0 )\n",
    "        self.x1 = self.fc2.forward( self.s1 )\n",
    "        self.s2 = self.fc3.forward( self.x1 )\n",
    "        self.x2 = self.fc2.forward( self.s2 ) \n",
    "        return self.x2\n",
    "    def backward(self, dloss):\n",
    "        dl_dx2 = dloss\n",
    "        dl_ds2 = self.fc2.backward(self.s2) * dl_dx2\n",
    "        dl_dx1 = self.fc3.backward(dl_ds2)\n",
    "        dl_ds1 = self.fc2.backward(self.s1) * dl_dx1\n",
    "        \n",
    "        dl_dwfc3.add_(dl_ds2.view(-1, 1).mm(self.x1.view(1, -1)))\n",
    "        dl_dbfc3.add_(dl_ds2)\n",
    "        dl_dwfc1.add_(dl_ds1.view(-1, 1).mm(self.x0.view(1, -1)))\n",
    "        dl_dbfc1.add_(dl_ds1)\n",
    "        \n",
    "        return dl_dwfc1, dl_dbfc1, dl_dwfc3, dl_dbfc3\n",
    "    \n",
    "    def update_all_parameters( self ):\n",
    "        return []\n",
    "    \n",
    "model4 = Net(100)\n",
    "criterion = MSEloss()\n",
    "output = model4.forward(train_input)\n",
    "dloss = criterion.backward(output, train_target)\n",
    "dl_dwfc1, dl_dbfc1, dl_dwfc3, dl_dbfc3 = model4.backward(dloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model4.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 3.1233e-04  2.1430e-03\n",
      " 4.1766e-04 -4.4921e-04\n",
      " 1.1467e-03  2.1319e-03\n",
      "           â‹®            \n",
      "-1.8960e-04  9.3419e-05\n",
      "-1.6098e-03 -1.8226e-04\n",
      " 1.4650e-03 -7.8535e-04\n",
      "[torch.FloatTensor of size 1000x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor(1000, 2).normal_(0, 1e-3)\n",
    "b = torch.Tensor(1000, 2).normal_(0, 1e-3)\n",
    "c = 2 * (a.sub(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "\n",
    "train_input, train_target = Variable(train_input), Variable(train_target)\n",
    "test_input, test_target = Variable(test_input), Variable(test_target)\n",
    "\n",
    "mini_batch_size = 100\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 1e-1)\n",
    "\n",
    "def train_model(model, train_input, train_target):\n",
    "    nb_epochs = 250\n",
    "\n",
    "    for e in range(0, nb_epochs):\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "def create_shallow_model():\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(2, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-0.6942 -0.3747\n",
      "-0.5409  0.1554\n",
      " 0.3436  0.2803\n",
      "-0.1926 -0.0961\n",
      " 0.6756 -0.1201\n",
      "-0.3381  0.1005\n",
      " 0.1184 -0.3067\n",
      " 0.5240  0.3154\n",
      "-0.2419  0.1664\n",
      " 0.3632 -0.0056\n",
      "-0.6728  0.1585\n",
      " 0.6073  0.0428\n",
      " 0.1415  0.0611\n",
      "-0.2524 -0.0338\n",
      " 0.6873  0.5168\n",
      "-0.0284 -0.1292\n",
      "-0.2894 -0.6843\n",
      " 0.2632 -0.1540\n",
      " 0.6541 -0.0701\n",
      " 0.2755  0.6429\n",
      " 0.0607 -0.5694\n",
      " 0.0917  0.4707\n",
      "-0.2657  0.2632\n",
      "-0.6404 -0.4735\n",
      " 0.3192  0.3457\n",
      " 0.5976  0.4233\n",
      "-0.4498  0.7069\n",
      "-0.5443  0.3204\n",
      "-0.6347  0.6735\n",
      "-0.4395 -0.2654\n",
      " 0.5578 -0.1573\n",
      " 0.2167 -0.1489\n",
      " 0.1859 -0.6394\n",
      " 0.6642 -0.4088\n",
      " 0.1396 -0.5506\n",
      " 0.3834 -0.6786\n",
      " 0.1033 -0.4065\n",
      "-0.0743 -0.5520\n",
      "-0.4050  0.3709\n",
      "-0.0510  0.6013\n",
      "-0.6080  0.4766\n",
      " 0.3596 -0.2839\n",
      "-0.3375  0.5258\n",
      "-0.0922 -0.2590\n",
      " 0.3924  0.5540\n",
      " 0.6163 -0.6205\n",
      "-0.6690 -0.6774\n",
      "-0.2989  0.3123\n",
      " 0.2629  0.3536\n",
      " 0.3916  0.3715\n",
      " 0.1547  0.6609\n",
      "-0.6499  0.4555\n",
      "-0.0116 -0.0233\n",
      "-0.6125 -0.7019\n",
      " 0.0058 -0.5175\n",
      " 0.6603 -0.4861\n",
      "-0.4113 -0.4441\n",
      "-0.4775  0.0459\n",
      " 0.0209 -0.4182\n",
      " 0.6285 -0.3778\n",
      " 0.6710  0.5616\n",
      " 0.4646  0.2513\n",
      "-0.0767 -0.4056\n",
      " 0.2141 -0.5509\n",
      "-0.2328 -0.0939\n",
      "-0.1438  0.1539\n",
      "-0.3140  0.3924\n",
      " 0.6154 -0.2818\n",
      " 0.1684  0.6222\n",
      " 0.1231 -0.5293\n",
      " 0.0454 -0.5381\n",
      "-0.2721 -0.0067\n",
      "-0.3672  0.4725\n",
      "-0.3062  0.6920\n",
      " 0.6641  0.6987\n",
      "-0.3595 -0.1752\n",
      "-0.5843 -0.1896\n",
      " 0.2472 -0.0349\n",
      " 0.0041 -0.0930\n",
      " 0.0362  0.6667\n",
      " 0.5653  0.5165\n",
      "-0.1323  0.2856\n",
      " 0.6806 -0.2247\n",
      "-0.5294 -0.2222\n",
      " 0.1584  0.5230\n",
      "-0.5751 -0.3093\n",
      " 0.3102  0.2964\n",
      " 0.6437  0.5878\n",
      "-0.3124 -0.1627\n",
      " 0.3537  0.2942\n",
      "-0.5787  0.1253\n",
      " 0.2770  0.1737\n",
      " 0.6827  0.4891\n",
      " 0.6760 -0.3367\n",
      "-0.1920  0.6994\n",
      "-0.6719  0.0397\n",
      " 0.6621 -0.2086\n",
      "-0.1619 -0.5928\n",
      "-0.5367  0.0493\n",
      " 0.6507  0.6012\n",
      "-0.5200 -0.5899\n",
      " 0.1486 -0.4822\n",
      " 0.5706  0.5060\n",
      "-0.5734 -0.1745\n",
      "-0.3358 -0.3738\n",
      " 0.0349 -0.5916\n",
      "-0.1727  0.3111\n",
      " 0.0266  0.3233\n",
      " 0.1129  0.2936\n",
      "-0.0808 -0.0064\n",
      " 0.2796  0.2587\n",
      "-0.4605  0.4947\n",
      " 0.4158  0.4565\n",
      "-0.2243 -0.1171\n",
      " 0.4392  0.6517\n",
      " 0.4111  0.5409\n",
      "-0.5662 -0.6022\n",
      "-0.0124 -0.6961\n",
      " 0.6508  0.6112\n",
      "-0.7002  0.1672\n",
      " 0.2651 -0.3134\n",
      "-0.0539  0.0486\n",
      " 0.6180 -0.6631\n",
      " 0.1191 -0.4855\n",
      " 0.4993 -0.4626\n",
      " 0.1615 -0.0401\n",
      "-0.5192 -0.4652\n",
      " 0.4243  0.2480\n",
      "[torch.FloatTensor of size 128x2]\n",
      "\n",
      "\n",
      "-0.1070\n",
      "-0.5326\n",
      " 0.5479\n",
      "-0.2723\n",
      " 0.6657\n",
      " 0.3094\n",
      "-0.5047\n",
      " 0.1649\n",
      " 0.2211\n",
      " 0.4152\n",
      "-0.0222\n",
      "-0.1486\n",
      "-0.1744\n",
      " 0.0505\n",
      "-0.5286\n",
      "-0.0165\n",
      " 0.2362\n",
      "-0.4475\n",
      " 0.5581\n",
      "-0.6534\n",
      " 0.1223\n",
      " 0.1419\n",
      " 0.4782\n",
      "-0.6785\n",
      "-0.1735\n",
      " 0.2267\n",
      " 0.4184\n",
      " 0.6278\n",
      "-0.3678\n",
      "-0.5518\n",
      " 0.6947\n",
      "-0.6206\n",
      " 0.5321\n",
      "-0.3353\n",
      " 0.3210\n",
      " 0.4649\n",
      " 0.3043\n",
      " 0.5528\n",
      "-0.6955\n",
      "-0.3815\n",
      " 0.1184\n",
      "-0.5997\n",
      " 0.6227\n",
      " 0.2115\n",
      "-0.2305\n",
      "-0.5504\n",
      " 0.0030\n",
      "-0.1451\n",
      " 0.6498\n",
      " 0.0525\n",
      " 0.5544\n",
      " 0.6821\n",
      "-0.5300\n",
      " 0.2422\n",
      " 0.5710\n",
      " 0.1028\n",
      " 0.1903\n",
      "-0.6003\n",
      "-0.6724\n",
      " 0.2348\n",
      " 0.0939\n",
      " 0.1994\n",
      " 0.0047\n",
      " 0.0767\n",
      "-0.3879\n",
      " 0.6430\n",
      " 0.4806\n",
      " 0.5542\n",
      " 0.4414\n",
      "-0.2262\n",
      "-0.0235\n",
      "-0.2209\n",
      "-0.3702\n",
      " 0.5843\n",
      "-0.6183\n",
      " 0.6162\n",
      " 0.5931\n",
      "-0.0959\n",
      "-0.3245\n",
      " 0.4622\n",
      "-0.4445\n",
      " 0.6582\n",
      " 0.3051\n",
      " 0.1610\n",
      " 0.6479\n",
      "-0.4519\n",
      " 0.3416\n",
      "-0.0855\n",
      "-0.1719\n",
      "-0.1533\n",
      " 0.4515\n",
      "-0.2539\n",
      "-0.2214\n",
      "-0.1122\n",
      "-0.5889\n",
      "-0.1572\n",
      "-0.4925\n",
      "-0.0275\n",
      " 0.1091\n",
      " 0.4810\n",
      " 0.2692\n",
      " 0.2946\n",
      "-0.0039\n",
      " 0.0735\n",
      "-0.1434\n",
      " 0.3353\n",
      "-0.2937\n",
      " 0.6651\n",
      " 0.1794\n",
      " 0.5040\n",
      " 0.4067\n",
      "-0.1291\n",
      " 0.0909\n",
      "-0.0943\n",
      "-0.5853\n",
      "-0.4503\n",
      " 0.3359\n",
      " 0.1158\n",
      "-0.3879\n",
      "-0.5365\n",
      "-0.2781\n",
      "-0.2736\n",
      "-0.2420\n",
      " 0.1851\n",
      "-0.5532\n",
      "-0.6544\n",
      " 0.5585\n",
      "-0.0825\n",
      "[torch.FloatTensor of size 128]\n",
      "\n",
      "\n",
      "\n",
      "Columns 0 to 9 \n",
      "1.00000e-02 *\n",
      "  5.6947 -0.0911  3.8290  8.0484  4.7230  6.4712  5.0060 -4.3025  6.7933  1.1125\n",
      "  5.5638  2.8350  0.9046  2.5841  6.4826 -4.5158 -1.3524 -5.5937 -7.6711 -1.3001\n",
      "\n",
      "Columns 10 to 19 \n",
      "1.00000e-02 *\n",
      "  0.9121 -5.7364  7.0524  3.9516 -7.1684  2.4567 -1.8502  4.6185 -4.6801  6.7890\n",
      " -6.2497 -1.5638  6.7643  3.9537  5.9055  7.5997 -1.3519  2.1700 -7.4984  2.1353\n",
      "\n",
      "Columns 20 to 29 \n",
      "1.00000e-02 *\n",
      " -6.5481  2.3418 -1.4986 -8.3794  8.2815  6.8282  5.4723 -3.8281  5.5093  4.1214\n",
      "  3.5560  0.2447 -3.3504  4.8018  2.7197 -8.7960  3.6166  8.7746  0.2605  2.3801\n",
      "\n",
      "Columns 30 to 39 \n",
      "1.00000e-02 *\n",
      " -8.7503  1.9387  5.7512 -8.8364 -1.8446 -6.9169  6.6336 -8.4601 -3.1303 -7.6489\n",
      "  6.8533  8.6224  5.0039 -8.2966 -5.7928 -5.0573 -3.5561 -5.5433  4.7515  3.8238\n",
      "\n",
      "Columns 40 to 49 \n",
      "1.00000e-02 *\n",
      " -4.1184  7.3734  4.6056  8.5164  3.8695  4.3500  8.5832 -8.6911 -1.8030  0.9811\n",
      " -5.2810 -3.8334 -2.0634  6.5803 -4.7667 -0.9179  2.3725 -0.6103 -1.7169  3.0963\n",
      "\n",
      "Columns 50 to 59 \n",
      "1.00000e-02 *\n",
      " -1.7909 -6.4934 -3.4545  3.3124  8.5941  0.8513  6.4630  3.4248 -8.1507 -6.8099\n",
      "  7.3559  5.7862  3.0537  8.5531 -5.8214  6.3919  5.7222  3.6539  1.2755  7.0334\n",
      "\n",
      "Columns 60 to 69 \n",
      "1.00000e-02 *\n",
      "  0.1997  8.7933  6.7981 -0.1884  2.5895 -5.7895  8.0642  0.8765 -0.3480  6.8465\n",
      " -1.9177 -3.6080 -2.6599  8.2748  7.3370 -0.0312  0.9679 -6.9445 -3.9238  3.8505\n",
      "\n",
      "Columns 70 to 79 \n",
      "1.00000e-02 *\n",
      " -2.0175 -8.4238 -1.0952 -3.7901  5.8442  5.1686  3.1477  3.9127 -6.8511 -8.0263\n",
      " -3.8752  8.2041 -8.0899  8.2269 -7.4579  3.8315 -8.3675  6.7043  2.7470 -7.0660\n",
      "\n",
      "Columns 80 to 89 \n",
      "1.00000e-02 *\n",
      "  5.6276 -8.5707 -7.0126  1.3324  5.3746  0.8153  6.6296 -5.4068  6.8007  4.7076\n",
      "  1.5418 -2.6535 -8.3782  1.9207 -8.4047 -5.0551 -7.8242 -6.8295 -2.0127  8.6246\n",
      "\n",
      "Columns 90 to 99 \n",
      "1.00000e-02 *\n",
      "  6.6174 -5.2715  1.7064 -4.8142  2.7175 -0.3854  2.5970 -4.6885  3.5000 -5.3694\n",
      "  1.9450  4.5863  0.7401 -7.0352 -8.1867 -3.9104 -1.9280 -1.1965 -3.9736  2.7632\n",
      "\n",
      "Columns 100 to 109 \n",
      "1.00000e-02 *\n",
      "  7.7453  3.6705 -2.5914 -0.2927 -0.0700 -6.9938  2.2951  8.0816 -3.1484  7.7327\n",
      "  4.9796 -5.9000 -7.2023  3.7512 -1.5712 -4.8303 -1.9287  8.2132  8.5702 -4.1059\n",
      "\n",
      "Columns 110 to 119 \n",
      "1.00000e-02 *\n",
      " -5.0407 -5.8279 -7.0420  6.4528  0.0231  5.9321 -1.7978  5.5231  2.3076 -4.2946\n",
      " -2.8313  8.3334 -5.3372  5.0516  8.0379 -2.9840  7.9099  4.7107  6.8219 -2.3091\n",
      "\n",
      "Columns 120 to 127 \n",
      "1.00000e-02 *\n",
      " -1.4205 -8.2760  3.8676 -7.1009 -8.4409  2.8788 -4.7436  4.2875\n",
      " -0.0515 -0.8419 -1.0635 -3.7744 -7.0707  1.5051  2.9310 -0.8765\n",
      "[torch.FloatTensor of size 2x128]\n",
      "\n",
      "\n",
      "1.00000e-02 *\n",
      " -6.3833\n",
      "  0.7715\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = create_shallow_model()\n",
    "for param in model.parameters():\n",
    "    print (param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-0.2673  0.3985\n",
      "-0.4782  0.5297\n",
      " 0.1251 -0.1143\n",
      " 0.2737 -0.6261\n",
      "[torch.FloatTensor of size 4x2]\n",
      "\n",
      "\n",
      "-0.6262\n",
      "-0.4391\n",
      " 0.2651\n",
      " 0.3366\n",
      "[torch.FloatTensor of size 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print (param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
